{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import model_selection\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_val_score, ShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import SGDClassifier, HuberRegressor, SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, QuantileTransformer, PowerTransformer, PolynomialFeatures, KBinsDiscretizer\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import base\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Standard plotly imports\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': 20,\n",
    "          'figure.figsize': (15, 10),\n",
    "         'axes.labelsize': 20,\n",
    "         'axes.titlesize': 20,\n",
    "         'xtick.labelsize': 20,\n",
    "         'ytick.labelsize': 20}\n",
    "pylab.rcParams.update(params)\n",
    "plt.close('all')\n",
    "\n",
    "## Files are stored in the '2015' and '2016' subdirectories, relative to the working directory\n",
    "path2015 = Path('../2015')\n",
    "path2016 = Path('../2016')\n",
    "dp = np.linspace(0,100,11)\n",
    "dy = np.linspace(1945,2020,15)\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Column names in the 2016 version of the Physician Compare National Downloadable File are simple and coding-friendly \n",
    "## except for a leading space in all columns after the first. That file is read first and its column names (with leading \n",
    "## space removed) used to replace column names of the 2015 version data after its file is read. Numerical columns are read \n",
    "## as floats (many have NaNs), except where that failed due to presence of a string. As of now, these are handled, when \n",
    "## necessary, on a case-by-case basis. ndf16.dtypes.equals(ndf15.dtypes) returns True.\n",
    "\n",
    "#col_names16 = pd.read_csv(path2016 / 'Physician_Compare_National_Downloadable_File.csv', nrows=0).columns\n",
    "#types_dict = {\"NPI\": float, \" Ind_PAC_ID\": float, \" Grd_yr\": float, \" org_pac_id\": float, \" num_org_mem\": float}\n",
    "#types_dict.update({col: str for col in col_names16 if col not in types_dict})\n",
    "ndf16 = pd.read_csv(path2016 / 'Physician_Compare_National_Downloadable_File.csv').rename(columns=lambda x: x.strip()).rename(columns=lambda x: x.lower())\n",
    "\n",
    "#col_names16 = pd.read_csv(path2016 / 'Physician_Compare_2016_Individual_EP_Public_Reporting.csv', nrows=0).columns\n",
    "#types_dict = {\"NPI\": float, \" Ind_PAC_ID\": float, \" prf_rate\": float, \" patient_count\": float}\n",
    "#types_dict.update({col: str for col in col_names16 if col not in types_dict})\n",
    "ips16 = pd.read_csv(path2016 / 'Physician_Compare_2016_Individual_EP_Public_Reporting.csv').rename(columns=lambda x: x.strip()).rename(columns=lambda x: x.lower())\n",
    "\n",
    "census_regions = pd.read_csv('../us_census_bureau_regions_and_divisions.csv')\n",
    "census_regions.rename(index=str, columns={'State Code':'st'}, inplace=True)\n",
    "census_regions.rename(str.lower, axis='columns', inplace=True)\n",
    "\n",
    "ndf16['org_pac_id'] = ndf16['org_pac_id'].astype(str)\n",
    "ndf16['npi'] = ndf16['npi'].astype(str)\n",
    "ndf16['hosp_afl_1'] = ndf16['hosp_afl_1'].astype(str)\n",
    "ndf16['hosp_afl_2'] = ndf16['hosp_afl_2'].astype(str)\n",
    "ndf16['hosp_afl_3'] = ndf16['hosp_afl_3'].astype(str)\n",
    "ndf16['hosp_afl_4'] = ndf16['hosp_afl_4'].astype(str)\n",
    "ndf16['hosp_afl_5'] = ndf16['hosp_afl_5'].astype(str)\n",
    "ndf16['hosps']=(ndf16.hosp_afl_1+' '+ndf16.hosp_afl_2+' '+ndf16.hosp_afl_3+' '+ndf16.hosp_afl_4+' '+ndf16.hosp_afl_5).str.replace('\\.0', '').str.replace('nan nan nan nan nan', '').str.replace(' nan', '')\n",
    "\n",
    "# Add feature for the average number of members in the practitioner's organization(s).\n",
    "ndf16['avg_num_org_mem'] = ndf16.groupby('npi')['num_org_mem'].transform('mean')\n",
    "# Transform the prf_rate for measures with invs_msr == Y. This makes it so that \n",
    "# a numerically greater score is desirable for *all* measures.\n",
    "#mdf.loc[mdf.invs_msr == 'Y', 'prf_rate'] = 100 - mdf.loc[mdf.invs_msr == 'Y', 'prf_rate']\n",
    "# Add census Region and Division features to records based on state.\n",
    "# https://github.com/cphalpert/census-regions/blob/master/us%20census%20bureau%20regions%20and%20divisions.csv\n",
    "# Check for any with more than 1 state first\n",
    "mdf['npi_num_st'] = mdf.groupby('npi')['st'].transform('nunique')\n",
    "mdf['npi_num_zip'] = mdf.groupby('npi')['zip'].transform('nunique')\n",
    "mdf['npi_num_measures'] = mdf.groupby('npi')['measure_id'].transform('nunique')\n",
    "\n",
    "org_pac_ids = ndf16.groupby(['npi'])['org_pac_id'].unique().to_frame()\n",
    "ndf16_org_pac_ids = pd.merge(ndf16, org_pac_ids, on='npi', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ips_ndf16 = pd.merge(ips16, ndf16_org_pac_ids, on='npi', how='left')\n",
    "mdf16 = pd.merge(ips_ndf16, census_regions, on='st', how='left')\n",
    "\n",
    "# Replace NaN's in mhi, ehr, and assgn with 'N' for \"No\" to complement the 'Y' values \n",
    "values = {'mhi': 'N', 'ehr': 'N', 'assgn': 'N', 'sec_spec_1':'None', 'sec_spec_2':'None', 'sec_spec_3':'None', 'sec_spec_4':'None', 'hosp_afl_1':'None', 'hosp_afl_2':'None', 'hosp_afl_3':'None', 'hosp_afl_4':'None', 'hosp_afl_5':'None'}\n",
    "mdf16 = mdf16.fillna(value=values)\n",
    "\n",
    "\n",
    "\n",
    "# Feature engineering/manipulation\n",
    "\n",
    "\n",
    "'''\n",
    ">>>mdf16.columns\n",
    "\n",
    "Index(['npi', 'ind_pac_id_x', 'lst_nm_x', 'frst_nm_x', 'measure_id',\n",
    "       'measure_title', 'invs_msr', 'prf_rate', 'patient_count',\n",
    "       'collection_type', 'live_site_ind', 'ind_pac_id_y', 'ind_enrl_id',\n",
    "       'lst_nm_y', 'frst_nm_y', 'mid_nm', 'suff', 'gndr', 'cred', 'med_sch',\n",
    "       'grd_yr', 'pri_spec', 'sec_spec_1', 'sec_spec_2', 'sec_spec_3',\n",
    "       'sec_spec_4', 'sec_spec_all', 'org_nm', 'org_pac_id', 'num_org_mem',\n",
    "       'adr_ln_1', 'adr_ln_2', 'ln_2_sprs', 'cty', 'st', 'zip', 'phn_numbr',\n",
    "       'hosp_afl_1', 'hosp_afl_lbn_1', 'hosp_afl_2', 'hosp_afl_lbn_2',\n",
    "       'hosp_afl_3', 'hosp_afl_lbn_3', 'hosp_afl_4', 'hosp_afl_lbn_4',\n",
    "       'hosp_afl_5', 'hosp_afl_lbn_5', 'assgn', 'pqrs', 'ehr', 'mhi', 'state',\n",
    "       'region', 'division'],\n",
    "      dtype='object')\n",
    "\n",
    ">>>print(mdf16.ind_pac_id_x.apply(str).describe())\n",
    ">>>print(mdf16.npi.apply(str).describe())\n",
    "                                        \n",
    "count           685489\n",
    "unique          126054\n",
    "top       5294718938.0\n",
    "freq               232                   One to one mapping between unique npi/ind_pac_id values. Using npi.\n",
    "Name: ind_pac_id_x, dtype: object\n",
    "\n",
    "count           685489\n",
    "unique          126054\n",
    "top       1861445538.0\n",
    "freq               232\n",
    "Name: npi, dtype: object\n",
    "\n",
    ">>>print(mdf16.org_nm.apply(str).describe())\n",
    ">>>print(mdf16.org_pac_id.apply(str).describe())\n",
    "\n",
    "count     685489\n",
    "unique     25618\n",
    "top          nan\n",
    "freq       63920\n",
    "Name: org_nm, dtype: object\n",
    "\n",
    "count     685489\n",
    "unique     25760 <-- Most likely explanation is that a small fraction of org_nm values are repeated. Using org_pac_id.\n",
    "top          nan\n",
    "freq       63920\n",
    "Name: org_pac_id, dtype: object\n",
    "\n",
    ">>>print(mdf16.hosp_afl_1.apply(str).describe())\n",
    ">>>print(mdf16.hosp_afl_lbn_1.apply(str).describe())\n",
    "\n",
    "count     685489\n",
    "unique      4494 <-- *Many* hospital names repeated, as expected. Using hosp_afl_1, etc. as unique categorical variables. \n",
    "top          nan\n",
    "freq      185183\n",
    "Name: hosp_afl_1, dtype: object\n",
    "\n",
    "count     685489\n",
    "unique      3437\n",
    "top          nan\n",
    "freq      185295\n",
    "Name: hosp_afl_lbn_1, dtype: object\n",
    "\n",
    ">>>print(mdf16.npi.apply(str).describe())\n",
    ">>>mdf16[mdf16.groupby('npi')['st'].transform('nunique').ge(2)].pri_spec.describe()\n",
    ">>>mdf16[mdf16.groupby('npi')['st'].transform('nunique').ge(2)].npi.apply(str).describe()\n",
    "\n",
    "count           685489\n",
    "unique          126054\n",
    "top       1861445538.0\n",
    "freq               232\n",
    "Name: npi, dtype: object\n",
    "\n",
    "count                    64836 <-- About 10% of total observations involve providers with an address in more than one state\n",
    "unique                      68\n",
    "top       DIAGNOSTIC RADIOLOGY\n",
    "freq                     35041  \n",
    "Name: pri_spec, dtype: object\n",
    "\n",
    "count            64836\n",
    "unique            5555 <-- Less than 5% of providers. For now, will filter our observations # of states for a provider > 1.\n",
    "top       1639315260.0\n",
    "freq               115\n",
    "Name: npi, dtype: object\n",
    "\n",
    "'''\n",
    "\n",
    "# Numerical features worth keeping\n",
    "# ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "\n",
    "# Categorical features worth keeping (using measure_id rather than measure_title, since some titles were repeated).\n",
    "# That is probably inconsequential since measure_id's with fewer than 100 observations are being filtered, \n",
    "# dropping the number considerably. ~84 to ~52?\n",
    "# ['npi', 'measure_id', 'gndr', 'med_sch', 'pri_spec', 'sec_spec_1', 'sec_spec_2', 'sec_spec_3', 'sec_spec_4', 'org_nm', 'org_pac_id', 'hosp_afl_1',  'hosp_afl_2', 'hosp_afl_3', 'hosp_afl_4', 'hosp_afl_5', 'assgn', 'ehr', 'mhi', 'st', 'region', 'division']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mdf16.columns\n",
    "\n",
    "Index(['npi', 'ind_pac_id_x', 'lst_nm_x', 'frst_nm_x', 'measure_id',\n",
    "       'measure_title', 'invs_msr', 'prf_rate', 'patient_count',\n",
    "       'collection_type', 'live_site_ind', 'ind_pac_id_y', 'ind_enrl_id',\n",
    "       'lst_nm_y', 'frst_nm_y', 'mid_nm', 'suff', 'gndr', 'cred', 'med_sch',\n",
    "       'grd_yr', 'pri_spec', 'sec_spec_1', 'sec_spec_2', 'sec_spec_3',\n",
    "       'sec_spec_4', 'sec_spec_all', 'org_nm', 'org_pac_id', 'num_org_mem',\n",
    "       'adr_ln_1', 'adr_ln_2', 'ln_2_sprs', 'cty', 'st', 'zip', 'phn_numbr',\n",
    "       'hosp_afl_1', 'hosp_afl_lbn_1', 'hosp_afl_2', 'hosp_afl_lbn_2',\n",
    "       'hosp_afl_3', 'hosp_afl_lbn_3', 'hosp_afl_4', 'hosp_afl_lbn_4',\n",
    "       'hosp_afl_5', 'hosp_afl_lbn_5', 'assgn', 'pqrs', 'ehr', 'mhi', 'state',\n",
    "       'region', 'division'],\n",
    "      dtype='object')\n",
    "\n",
    "print(mdf16.ind_pac_id_x.apply(str).describe())\n",
    "print(mdf16.npi.apply(str).describe())\n",
    "                                        \n",
    "count           685489\n",
    "unique          126054\n",
    "top       5294718938.0\n",
    "freq               232   One to one mapping between unique npi/ind_pac_id values. Using npi.\n",
    "Name: ind_pac_id_x, dtype: object\n",
    "\n",
    "count           685489\n",
    "unique          126054\n",
    "top       1861445538.0\n",
    "freq               232\n",
    "Name: npi, dtype: object\n",
    "\n",
    "print(mdf16.org_nm.apply(str).describe())\n",
    "print(mdf16.org_pac_id.apply(str).describe())\n",
    "\n",
    "count     685489\n",
    "unique     25618\n",
    "top          nan\n",
    "freq       63920\n",
    "Name: org_nm, dtype: object\n",
    "\n",
    "count     685489\n",
    "unique     25760 <-- Most likely explanation is that a small fraction of org_nm values are repeated. Using org_pac_id.\n",
    "top          nan\n",
    "freq       63920\n",
    "Name: org_pac_id, dtype: object\n",
    "\n",
    "print(mdf16.hosp_afl_1.apply(str).describe())\n",
    "print(mdf16.hosp_afl_lbn_1.apply(str).describe())\n",
    "\n",
    "count     685489\n",
    "unique      4494 <-- *Many* hospital names repeated, as expected. Using hosp_afl_1, etc. as unique categorical variables. \n",
    "top          nan\n",
    "freq      185183\n",
    "Name: hosp_afl_1, dtype: object\n",
    "\n",
    "count     685489\n",
    "unique      3437\n",
    "top          nan\n",
    "freq      185295\n",
    "Name: hosp_afl_lbn_1, dtype: object\n",
    "\n",
    "print(mdf16.npi.apply(str).describe())\n",
    "print(mdf16[mdf16.groupby('npi')['st'].transform('nunique').ge(2)].pri_spec.describe())\n",
    "print(mdf16[mdf16.groupby('npi')['st'].transform('nunique').ge(2)].npi.apply(str).describe())\n",
    "\n",
    "count           685489\n",
    "unique          126054\n",
    "top       1861445538.0\n",
    "freq               232\n",
    "Name: npi, dtype: object\n",
    "\n",
    "count                    64836 <-- About 10% of total observations involve providers with an address in more than one state\n",
    "unique                      68\n",
    "top       DIAGNOSTIC RADIOLOGY\n",
    "freq                     35041  \n",
    "Name: pri_spec, dtype: object\n",
    "\n",
    "count            64836\n",
    "unique            5555 <-- Less than 5% of providers. For now, will filter our observations # of states for a provider > 1.\n",
    "top       1639315260.0\n",
    "freq               115\n",
    "Name: npi, dtype: object\n",
    "\n",
    "'''\n",
    "\n",
    "# Numerical features worth keeping\n",
    "['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "\n",
    "# Categorical features worth keeping (using measure_id rather than measure_title, since some titles were repeated).\n",
    "# That is probably inconsequential since measure_id's with fewer than 100 observations are being filtered, dropping the number considerably. ~84 to ~52?\n",
    "['npi', 'measure_id', 'gndr', 'med_sch', 'pri_spec', 'sec_spec_1', 'sec_spec_2', 'sec_spec_3', 'sec_spec_4', 'org_nm', 'org_pac_id', 'hosp_afl_1',  'hosp_afl_2', 'hosp_afl_3', 'hosp_afl_4', 'hosp_afl_5', 'assgn', 'ehr', 'mhi', 'st', 'region', 'division']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mdf16.columns)\n",
    "#mdf16.head(30)\n",
    "#mdf16.loc[mdf16.org_nm == 'ANMED HEALTH']\n",
    "#mdf16[mdf16.groupby('npi')['st'].transform('nunique').ge(2)].npi.apply(str).describe()\n",
    "#temp = mdf16[['grd_yr', 'patient_count', 'npi', 'measure_id', 'gndr', 'med_sch', 'pri_spec', 'sec_spec_1', 'sec_spec_2', 'sec_spec_3', 'sec_spec_4', 'org_nm', 'org_pac_id', 'hosp_afl_1',  'hosp_afl_2', 'hosp_afl_3', 'hosp_afl_4', 'hosp_afl_5', 'assgn', 'ehr', 'mhi', 'st', 'region', 'division']]\n",
    "#mdf16.pivot(index='npi', columns='org_nm')\n",
    "#temp\n",
    "\n",
    "mdf16\n",
    "#ndf16[ndf16.groupby('npi')['org_pac_id'].transform('nunique').ge(18)]\n",
    "#ndf16['org_pac_ids'] = \n",
    "\n",
    "# Want to get unique (org_nm, org_pac_id, num_org_mem)\n",
    "# One provider with 18 different org_pac_id!\n",
    "# Build 2 new columns, one with string representations of org_pac_id memberships, the other of hosp_afl_*'s\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               490126 490048\n",
       "1                               140010 140281\n",
       "2                               140010 140281\n",
       "3                               140010 140281\n",
       "4                               140010 140281\n",
       "5                               140010 140281\n",
       "6                               140010 140281\n",
       "7                               140010 140281\n",
       "8                               140010 140281\n",
       "9                               140010 140281\n",
       "10                360112 360262 360081 360074\n",
       "11                360112 360262 360081 360074\n",
       "12                360112 360262 360081 360074\n",
       "13                360112 360262 360081 360074\n",
       "14                360112 360262 360081 360074\n",
       "15                                           \n",
       "16                                     360098\n",
       "17                                      60024\n",
       "18                                      60024\n",
       "19                                     100072\n",
       "20                                     100072\n",
       "21                                     100072\n",
       "22                                     100072\n",
       "23                                     100072\n",
       "24                              390035 390049\n",
       "25                              390035 390049\n",
       "26                              390035 390049\n",
       "27         370001 370202 370183 370057 370039\n",
       "28                                      50262\n",
       "29                                      50262\n",
       "                          ...                \n",
       "2031901                                      \n",
       "2031902                                      \n",
       "2031903                                      \n",
       "2031904                                220084\n",
       "2031905                                      \n",
       "2031906                                200019\n",
       "2031907                         380017 381317\n",
       "2031908           450184 450862 670122 670059\n",
       "2031909                  100007 100030 100051\n",
       "2031910                                      \n",
       "2031911                                 50609\n",
       "2031912                                 50609\n",
       "2031913                                 50609\n",
       "2031914                                 50609\n",
       "2031915                                      \n",
       "2031916                                      \n",
       "2031917                                100168\n",
       "2031918                                100168\n",
       "2031919                                100052\n",
       "2031920                                100052\n",
       "2031921                                      \n",
       "2031922                                 50115\n",
       "2031923                                      \n",
       "2031924                                      \n",
       "2031925                                      \n",
       "2031926                                500005\n",
       "2031927                                500005\n",
       "2031928                                500005\n",
       "2031929                                500005\n",
       "2031930                                500005\n",
       "Name: hosps, Length: 2031931, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat(ndf16.hosp_afl_1[0], ndf16.hosp_afl_2[0], ndf16.hosp_afl_3[0], ndf16.hosp_afl_4[0], ndf16.hosp_afl_5[0])\n",
    "#ndf16.hosps[15] == ndf16.hosps[2031915]\n",
    "ndf16.hosps\n",
    "#type(ndf16.hosp_afl_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mdf_trim = mdf_loc.iloc[:, np.r_[0, 4, 5, 7, 8, 9, 17, 19, 20, 21, 47, 49, 50, 51, 52, 57, 58, 59]].drop_duplicates()\n",
    "# \n",
    "\n",
    "mdf_cln1 = mdf_fnl[['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures', 'measure_id', 'med_sch', 'pri_spec', 'assgn', 'ehr', 'mhi', 'state', 'region', 'gndr', 'prf_rate']].dropna()\n",
    "mdf_cln2 = mdf_cln1[mdf_cln1.groupby('measure_id')['measure_id'].transform('count').ge(100)]\n",
    "mdf_cln3 = mdf_cln2[mdf_cln2.groupby('med_sch')['med_sch'].transform('count').ge(100)]\n",
    "mdf_cln4 = mdf_cln3[mdf_cln3.groupby('pri_spec')['pri_spec'].transform('count').ge(100)]\n",
    "mdf_cln5 = mdf_cln4[mdf_cln3.groupby('state')['state'].transform('count').ge(100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "X = mdf_cln2.drop('prf_rate', axis=1)\n",
    "y = mdf_cln2['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id', 'med_sch', 'pri_spec']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "X = mdf_cln4.drop('prf_rate', axis=1)\n",
    "y = mdf_cln4['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id', 'med_sch', 'pri_spec', 'assgn', 'ehr', 'mhi', 'state', 'region', 'gndr']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "X = mdf_cln5.drop('prf_rate', axis=1)\n",
    "y = mdf_cln5['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id', 'med_sch', 'pri_spec', 'assgn', 'ehr', 'mhi', 'state', 'region', 'gndr']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('tsvd', TruncatedSVD(n_components=200, n_iter=7, random_state=42)),\n",
    "                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "X = mdf_cln5.drop('prf_rate', axis=1)\n",
    "y = mdf_cln5['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('rs', RobustScaler()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id', 'med_sch', 'pri_spec', 'assgn', 'ehr', 'mhi', 'state', 'region', 'gndr']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "X = mdf_cln5.drop('prf_rate', axis=1)\n",
    "y = mdf_cln5['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['grd_yr', 'patient_count', 'avg_num_org_mem', 'npi_num_measures']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('rs', RobustScaler()),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['measure_id', 'med_sch', 'pri_spec', 'assgn', 'ehr', 'mhi', 'state', 'region', 'gndr']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)\n",
    "#                      ('rfr', RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1)) \n",
    "                     ])\n",
    "\n",
    "\n",
    "\n",
    "X = mdf_cln5.drop('prf_rate', axis=1)\n",
    "y = mdf_cln5['prf_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "X_train = clf.fit_transform(X_train)\n",
    "X_test = clf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf_fnl.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data ndf16\n",
    "total = ndf16.isnull().sum().sort_values(ascending=False)\n",
    "percent = (ndf16.isnull().sum()/ndf16.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data ips16\n",
    "total = ips16.isnull().sum().sort_values(ascending=False)\n",
    "percent = (ips16.isnull().sum()/ips16.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf_fnl.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(mdf_fnl.prf_rate, hist=True);\n",
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % mdf_fnl.prf_rate.skew())\n",
    "print(\"Kurtosis: %f\" % mdf_fnl.prf_rate.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot grlivarea/saleprice\n",
    "var = 'prac_yrs'\n",
    "data = pd.concat([mdf_fnl['prf_rate'], mdf_fnl[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='prf_rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot overallqual/saleprice\n",
    "var = 'pri_spec'\n",
    "data = pd.concat([mdf_fnl['prf_rate'], mdf_fnl[var], mdf_fnl['gndr']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(100, 90))\n",
    "fig = sns.boxplot(x=var, y=\"prf_rate\", data=data, hue='gndr')\n",
    "fig.axis(ymin=0, ymax=105);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = mdf_fnl.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 5 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'prf_rate')['prf_rate'].index\n",
    "cm = np.corrcoef(mdf_fnl[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_lvl1_measure_title = data.groupby(by=['measure_title']).describe()\n",
    "describe_lvl1_med_sch = data.groupby(by=['med_sch']).describe()\n",
    "describe_lvl1_gndr = data.groupby(by=['gndr']).describe()\n",
    "describe_lvl1_grd_yr = data.groupby(by=['grd_yr']).describe()\n",
    "describe_lvl1_pri_spec = data.groupby(by=['pri_spec']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_lvl2_measure_title_pri_spec = data.groupby(by=['measure_title', 'pri_spec']).describe()\n",
    "describe_lvl2_pri_spec_measure_title = data.groupby(by=['pri_spec', 'measure_title']).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe_lvl1_pri_spec.sort_values('')\n",
    "#data.groupby(['measure_title']).filter(lambda x: x['measure_title'].count() < 100.).hist(by=data['prf_rate'], density=True)\n",
    "#data.groupby(['measure_title']).hist()\n",
    "\n",
    "grouper = data.groupby('measure_title')['prf_rate']\n",
    "\n",
    "for days in grouper.groups.keys():\n",
    "    grouper.get_group(measure_title).hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = data.groupby(['pri_spec', 'measure_title'])\n",
    "#data.groupby(level=0).describe()\n",
    "#.hist(by='', density=True, stacked=True)\n",
    "\n",
    "data['grd_yr'].hist(by=data['measure_title'], density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We name the file according to the E value, thus, we need to get all the values.\n",
    "# The following line is for this setting an overkill, however, in general very nice.\n",
    "\n",
    "# Get all unique E values \n",
    "uE = pd.Series(data.measure_title.values.ravel()).unique()\n",
    "# Sort them, this is the order the hist() command returns the E value histograms        \n",
    "uE.sort()\n",
    "\n",
    "# We could use an iterator, however, we use it more often than once,\n",
    "# thus, we use a counter\n",
    "curE = 0   \n",
    "\n",
    "# Go through all the histograms grouped to E\n",
    "for curHist in data.groupby(['grd_yr']).hist(by='measure_title', density=True):\n",
    "    # Select the figure \n",
    "    fig = curHist[0,0].get_figure()\n",
    "    # Add an overall title\n",
    "    fig.suptitle('Measure Title: %s' % uE[curE])\n",
    "    # Make it nice\n",
    "    fig.tight_layout()\n",
    "    # Save the figure\n",
    "    fig.savefig(\"../%s.png\" % uE[curE], dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    curE += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe_lvl2_measure_title_pri_spec.to_csv('../describe_lvl2_measure_title_pri_spec.csv', index=True)\n",
    "describe_lvl2_measure_title_pri_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_lvl1_pri_spec['prf_rate']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_lvl1_pri_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation of current medications\n",
    "PQRS_EP_130_overallmean = PQRS_EP_130['prf_rate'].mean()\n",
    "PQRS_EP_130['pri_spec_count'] = PQRS_EP_130.groupby('pri_spec')['pri_spec'].transform('count')\n",
    "PQRS_EP_130['med_sch_count'] = PQRS_EP_130.groupby('med_sch')['med_sch'].transform('count')\n",
    "PQRS_EP_130['gndr_count'] = PQRS_EP_130.groupby('gndr')['gndr'].transform('count')\n",
    "PQRS_EP_130['pri_spec_mean'] = PQRS_EP_130.groupby('pri_spec')['prf_rate'].transform('mean')\n",
    "PQRS_EP_130['med_sch_mean'] = PQRS_EP_130.groupby('med_sch')['prf_rate'].transform('mean')\n",
    "PQRS_EP_130['pri_spec_mean_ratio'] = PQRS_EP_130.groupby('pri_spec')['prf_rate'].transform('mean')/PQRS_EP_130_overallmean\n",
    "PQRS_EP_130['med_sch_mean_ratio'] = PQRS_EP_130.groupby('med_sch')['prf_rate'].transform('mean')/PQRS_EP_130_overallmean\n",
    "#PQRS_EP_130['gndr_mean'] = PQRS_EP_130.groupby('gndr')['gndr'].transform('mean')\n",
    "#PQRS_EP_130_overallmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PQRS_EP_130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PQRS_EP_130[['pri_spec', 'pri_spec_count', 'pri_spec_mean', 'pri_spec_mean_ratio']].drop_duplicates().sort_values(by='pri_spec_mean_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PQRS_EP_130[['med_sch', 'med_sch_count', 'med_sch_mean']].drop_duplicates().sort_values(by='med_sch_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tobacco use screening and cessation\n",
    "PQRS_EP_226['pri_spec_count'] = PQRS_EP_226.groupby('pri_spec')['pri_spec'].transform('count')\n",
    "PQRS_EP_226['med_sch_count'] = PQRS_EP_226.groupby('med_sch')['med_sch'].transform('count')\n",
    "PQRS_EP_226['gndr_count'] = PQRS_EP_226.groupby('gndr')['gndr'].transform('count')\n",
    "PQRS_EP_226['pri_spec_mean'] = PQRS_EP_226.groupby('pri_spec')['prf_rate'].transform('mean')\n",
    "PQRS_EP_226['med_sch_mean'] = PQRS_EP_226.groupby('med_sch')['prf_rate'].transform('mean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PQRS_EP_226[['pri_spec', 'pri_spec_count', 'pri_spec_mean']].drop_duplicates().sort_values(by='pri_spec_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PQRS_EP_226[['med_sch', 'med_sch_count', 'med_sch_mean']].drop_duplicates().sort_values(by='med_sch_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [[thing] for thing in mdf_fnl.prac_yrs], [[thing] for thing in mdf_fnl.prf_rate]\n",
    "\n",
    "cv = model_selection.ShuffleSplit(n_splits=20, test_size=0.2, random_state=42)\n",
    "param_grid = {\"knr__n_neighbors\": range(100, 141, 10)}    # parameters to Pipeline take the form [label]__[estimator_param]\n",
    "\n",
    "mdf_fnl_knn = Pipeline([('knr', KNeighborsRegressor(n_neighbors=5))\n",
    "                                     ])\n",
    "\n",
    "mdf_fnl_knn_cv = model_selection.GridSearchCV(mdf_fnl_knn, \n",
    "                                                param_grid=param_grid, cv=cv, \n",
    "                                                scoring='r2',\n",
    "                                                refit=True,\n",
    "                                                n_jobs=-1)\n",
    "mdf_fnl_knn_cv.fit(X, y)\n",
    "\n",
    "#param_grid = {\"rfr__max_depth\": (1, 2, 3, 4, 5, 6, 7)}    # parameters to Pipeline take the form [label]__[estimator_param]\n",
    "\n",
    "#td_rfr = Pipeline([('rfr', ('rfr', RandomForestRegressor(max_depth=7, random_state=0, n_estimators=100)))\n",
    "#                                     ])\n",
    "\n",
    "#td_rfr_cv = model_selection.GridSearchCV(td_rfr, \n",
    "#                                                       param_grid=param_grid, cv=cv, \n",
    "#                                                       scoring='r2',\n",
    "#                                                        refit=True)\n",
    "#td_rfr_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf_fnl_knn_cv_results = mdf_fnl_knn_cv.cv_results_\n",
    "mdf_fnl_knn_cv_r2 = pd.DataFrame.from_dict(\n",
    "    {'n_neighbors': [rec['knr__n_neighbors'] for rec in mdf_fnl_knn_cv_results['params']],\n",
    "    'r2': mdf_fnl_knn_cv_results['mean_test_score']})\n",
    "\n",
    "mdf_fnl_knn_cv_r2.r2\n",
    "plt.plot(mdf_fnl_knn_cv_r2.n_neighbors, mdf_fnl_knn_cv_r2.r2)\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('r2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf[['npi', 'measure_id', 'grd_yr', 'prf_rate']].drop_duplicates().sort_values(by='measure_id')\n",
    "#td = pd.concat([data[data.measure_id == 'PQRS_EP_109_1'], data[data.measure_id == 'PQRS_EP_110_1'], data[data.measure_id == 'PQRS_EP_111_1'], data[data.measure_id == 'PQRS_EP_112_1']])\n",
    "td = pd.concat([data[data.measure_id == 'PQRS_EP_130_1']])\n",
    "\n",
    "#X = mdf[['gndr', 'med_sch', 'grd_yr', 'pri_spec', 'num_org_mem']]\n",
    "#y = mdf[['prf_score']]\n",
    "#mdf\n",
    "# features\n",
    "#data\n",
    "g = sns.lmplot(x='grd_yr', y='prf_rate', col='measure_id', data=td,\n",
    "              col_wrap=3, ci=None, palette='muted', size=6,\n",
    "              scatter_kws={\"s\": 5, \"alpha\": 1})\n",
    "#g.set(ylim=(0, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "figure = ff.create_scatterplotmatrix(\n",
    "    td[['gndr', 'med_sch', 'grd_yr', 'pri_spec', 'prf_rate']].dropna(),\n",
    "    diag='histogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdf.pri_spec.unique().size\n",
    "def calc_stats(df, A, B):\n",
    "    print(A, B)\n",
    "    return scipy.stats.describe(mdf[(mdf.measure_id == A) & (mdf.pri_spec == B)].prf_rate)\n",
    "    \n",
    "A = mdf.measure_id.values\n",
    "B = mdf.pri_spec.values\n",
    "A, B    \n",
    "\n",
    "#df_xy['SUM_FUN0'], df_xy['SUM_FUN1'] = \n",
    "list(zip(*mdf.apply(lambda x: calc_stats(mdf, A, B), axis=1)))\n",
    "\n",
    "#mdf[mdf.measure_id == A && mdf.pri_spec == B]\n",
    "#mdf[(mdf.measure_id == 'PQRS_EP_111_1') & (mdf.pri_spec == 'INTERNAL MEDICINE')]\n",
    "\n",
    "#mdf[(mdf.measure_id == A) & (mdf.pri_spec == B)].prf_rate\n",
    "\n",
    "\n",
    "#scipy.stats.describe(mdf.prf_rate)\n",
    "#print(stats.ttest_ind(c1.prf_rate,c2.prf_rate,equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.meshgrid(mdf.measure_id.values.astype(str),\n",
    "                   mdf.pri_spec.values.astype(str))\n",
    "#mdf.pri_spec.values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'a':range(4),'b':range(4,8)})\n",
    "\n",
    "for a,b in zip(test.a, test.b): \n",
    "    print(a,b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of PQRS \"participation rate\", unique providers with PQRS == 'Y' to unique providers (PQRS either 'Y' or NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of PQRS \"participation rate\", unique providers with PQRS == 'Y' to unique providers (PQRS either 'Y' or NaN)\n",
    "\n",
    "ndf16trunc = ndf16.loc[:, 'NPI':'pri_spec'].drop_duplicates()\n",
    "ndf16trunc_pqrs = ndf16.loc[:, ['NPI', 'Ind_PAC_ID', 'lst_nm', 'frst_nm', 'Med_sch', 'Grd_yr', 'pri_spec', 'PQRS']].drop_duplicates()\n",
    "\n",
    "pqrs_y = ndf16trunc_pqrs.loc[ndf16trunc_pqrs.PQRS == 'Y', :].PQRS.count()\n",
    "pqrs_n = ndf16trunc_pqrs.PQRS.isna().count()\n",
    "participation_rate_overall = pqrs_y/(pqrs_y + pqrs_n)\n",
    "print(participation_rate_overall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_practitioners_per_measure = ips16.measure_title.value_counts()\n",
    "\n",
    "num_practitioners_per_measure.to_csv('../num_practitioners_per_measure.csv', index=True)\n",
    "#measure_names_descending_frequency = ips16.measure_title.value_counts().index\n",
    "\n",
    "#measure_names_descending_frequency_list = ips16.measure_title.value_counts().index.to_list()\n",
    "#ndf16trunc.loc[:, 'pri_spec'].value_counts().to_csv('../practitoners_per_specialty.csv', index=True)\n",
    "num_practitioners_per_specialty = ndf16trunc.loc[:, 'pri_spec'].value_counts()\n",
    "type(num_practitioners_per_measure.to_frame())\n",
    "num_practitioners_per_measure.to_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.qcut(ips16.NPI, 86)\n",
    "num_practitioners_per_measure.index[0]\n",
    "ips16.measure_title == num_practitioners_per_measure.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_count_per_measure = ips16.loc[:,:].groupby('measure_title').patient_count.sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_providers_in_ndf = ndf16trunc.NPI.drop_duplicates().count()\n",
    "num_unique_providers_in_ips = ips16.NPI.drop_duplicates().count()\n",
    "num_patients_treated = ips16.patient_count.sum()\n",
    "num_measures = ips16.measure_title.drop_duplicates().count()\n",
    "num_phys_specialties = ndf16trunc.pri_spec.drop_duplicates().count()\n",
    "\n",
    "num_unique_providers_in_ndf, num_unique_providers_in_ips, num_patients_treated, num_measures, num_phys_specialties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips16.measure_title.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## This code section examines Pneumonia Vaccination Status for Older Adults\n",
    "## Need to explore weighting performance scores by patient count for 2016 data, will be interesting to contrast with the 2015 \n",
    "## data where patient count is not available\n",
    "\n",
    "a = ips16.loc[(ips16['measure_ID']=='PQRS_EP_111_1'),['NPI','prf_rate','patient_count']].drop_duplicates().dropna()\n",
    "\n",
    "b1 = ndf16.loc[(ndf16['pri_spec']=='INTERNAL MEDICINE'),['NPI']].drop_duplicates().dropna()\n",
    "c1 = pd.merge(a, b1, on='NPI')\n",
    "\n",
    "b2 = ndf16.loc[(ndf16['pri_spec']=='INFECTIOUS DISEASE'),['NPI']].drop_duplicates().dropna()\n",
    "c2 = pd.merge(a, b2, on='NPI')\n",
    "\n",
    "b3 = ndf16.loc[(ndf16['pri_spec']=='EMERGENCY MEDICINE'),['NPI']].drop_duplicates().dropna()\n",
    "c3 = pd.merge(a, b3, on='NPI')\n",
    "\n",
    "b4 = ndf16.loc[(ndf16['pri_spec']=='PULMONARY DISEASE'),['NPI']].drop_duplicates().dropna()\n",
    "c4 = pd.merge(a, b4, on='NPI')\n",
    "\n",
    "b5 = ndf16.loc[(ndf16['pri_spec']=='NURSE PRACTITIONER'),['NPI']].drop_duplicates().dropna()\n",
    "c5 = pd.merge(a, b5, on='NPI')\n",
    "\n",
    "b6 = ndf16.loc[(ndf16['pri_spec']=='MEDICAL ONCOLOGY'),['NPI']].drop_duplicates().dropna()\n",
    "c6 = pd.merge(a, b6, on='NPI')\n",
    "\n",
    "b7 = ndf16.loc[(ndf16['pri_spec']=='GENERAL PRACTICE'),['NPI']].drop_duplicates().dropna()\n",
    "c7 = pd.merge(a, b7, on='NPI')\n",
    "\n",
    "b8 = ndf16.loc[(ndf16['pri_spec']=='PHYSICIAN ASSISTANT'),['NPI']].drop_duplicates().dropna()\n",
    "c8 = pd.merge(a, b8, on='NPI')\n",
    "\n",
    "\n",
    "print(scipy.stats.describe(c1.prf_rate))\n",
    "print(scipy.stats.describe(c2.prf_rate))\n",
    "print(scipy.stats.describe(c3.prf_rate))\n",
    "print(scipy.stats.describe(c4.prf_rate))\n",
    "print(scipy.stats.describe(c5.prf_rate))\n",
    "print(scipy.stats.describe(c6.prf_rate))\n",
    "print(scipy.stats.describe(c7.prf_rate))\n",
    "print(scipy.stats.describe(c8.prf_rate))\n",
    "\n",
    "print(stats.ttest_ind(c1.prf_rate,c2.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c1.prf_rate,c3.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c1.prf_rate,c4.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c2.prf_rate,c3.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c2.prf_rate,c4.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c3.prf_rate,c4.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c5.prf_rate,c8.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c2.prf_rate,c7.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c1.prf_rate,c5.prf_rate,equal_var=False))\n",
    "print(stats.ttest_ind(c1.prf_rate,c8.prf_rate,equal_var=False))\n",
    "print(1-58.85706462212487/75.30104623692203)\n",
    "print(1-59.421996879875195/75.30104623692203)\n",
    "print(1-62.54601226993865/75.30104623692203)\n",
    "print(1-63.55072463768116/75.30104623692203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_specialties = ndf16t.pri_spec.drop_duplicates()\n",
    "med_schools = ndf16t.Med_sch.drop_duplicates()\n",
    "measure_num_name_pairs = ips16[['measure_ID', 'measure_title']].drop_duplicates()\n",
    "measure_num_name_pairs\n",
    "\n",
    "#med_schools.drop_duplicates().to_csv('../med_sch.csv', index=False)\n",
    "#measure_num_name_pairs.drop_duplicates().to_csv('../measuretitles.csv', index=False)\n",
    "#phys_specialties.drop_duplicates().to_csv('../phys_specialties.csv', index=False)\n",
    "\n",
    "#phys_specialties\n",
    "#ips16[ips16['NPI','measure_ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dy = np.linspace(1945,2020,16)\n",
    "a16 = pd.value_counts(ndf16.loc[(ndf16['PQRS']=='Y'),['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "b16 = pd.value_counts(ndf16[['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "c16 = a16/b16\n",
    "ax = c16.plot.bar(ylim=(0,0.7), title='Clinician Participation Rate vs Year of Terminal Degree (2016 Data)')\n",
    "ax.set(xlabel=\"Year of Clinician's Terminal Degree\", ylabel=\"Clinician participation rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a16 = pd.value_counts(ndf16.loc[(ndf16['PQRS']=='Y'),['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "b16 = pd.value_counts(ndf16[['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "c16 = a16/b16\n",
    "ax = c16.plot.bar(ylim=(0,0.7), title='Clinician Participation Rate vs Year of Terminal Degree (2016 Data)')\n",
    "ax.set(xlabel=\"Year of Clinician's Terminal Degree\", ylabel=\"Clinician participation rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (c16/c15).iloc[0:13].plot.bar(ylim=(0.9,1.1), title='Participation rate change vs year of terminal degree (2016 data vs 2015 data)')\n",
    "ax.set(xlabel=\"Year of Clinician's Terminal Degree\", ylabel=\"Clinician participation rate year over year change\")\n",
    "#print((c16/c15).iloc[0:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It has been estimated that the total annual excess cost of hospital-treated pneumonia as a primary diagnosis in the elderly fee-for-service Medicare population in 2010 exceeded 7 billion dollars.\n",
    "\n",
    "# Takeaways from the above cursory comparisons of how clinicians of one primary specialty perform relative to clinicians of another primary specialty regarding how they advise their patients on Pneumonia Vaccination. \n",
    "\n",
    "# Physician Assistants (PAs) and Nurse Practitioners (NPs) do similarly well (p = 0.57) but both do significantly poorer than those whose primary specialty was Internal Medicine, with mean score 20% lower\n",
    "\n",
    "# Surprisingly, those whose primary specialty was Infectious Disease did significantly worse than Internal Medicine (p = 3e-08, Infectious Disease mean score 17% lower) and  Pulmonary Disease (p = 2e-05, Infectious Disease mean score 16% lower), but similarly to General Medicine (p = 0.8).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = df1.loc[(df1[\"Gender\"]==\"F\"), [\"Gender\"]]\n",
    "female_accept = df1.loc[(df1[\"Gender\"]==\"F\") & (df1[\"Professional accepts Medicare Assignment\"]==\"Y\"), [\"NPI\",\"PAC ID\",\"Medical school name\",\"Graduation year\"]]\n",
    "male = df1.loc[(df1[\"Gender\"]==\"M\"), [\"Gender\"]]\n",
    "male_accept = df1.loc[(df1[\"Gender\"]==\"M\") & (df1[\"Professional accepts Medicare Assignment\"]==\"Y\"), [\"NPI\",\"PAC ID\",\"Medical school name\",\"Graduation year\"]]\n",
    "am = df1.loc[(df1[\"Gender\"]==\"M\") & (df1[\"Professional accepts Medicare Assignment\"]==\"Y\"), [\"NPI\",\"Medical school name\",\"Graduation year\"]]\n",
    "af = df1.loc[(df1[\"Gender\"]==\"F\") & (df1[\"Professional accepts Medicare Assignment\"]==\"Y\"), [\"NPI\",\"Medical school name\",\"Graduation year\"]]\n",
    "df2_flu = df2.loc[(df2[\"Measure Title\"]==\"Preventive Care and Screening: Influenza Immunization\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df3_pneuvacc = df2.loc[(df2[\"Measure Title\"]==\"Pneumonia Vaccination Status for Older Adults\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df4_brcanc = df2.loc[(df2[\"Measure Title\"]==\"Breast Cancer Screening\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df5_colocanc = df2.loc[(df2[\"Measure Title\"]==\"Colorectal Cancer Screening\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df6_bmi = df2.loc[(df2[\"Measure Title\"]==\"Preventive Care and Screening: Body Mass Index (BMI) Screening and Follow-Up Plan\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df7_currmeds = df2.loc[(df2[\"Measure Title\"]==\"Documentation of Current Medications in the Medical Record\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df8_eldmal = df2.loc[(df2[\"Measure Title\"]==\"Elder Maltreatment Screen and Follow-Up Plan\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df9_tobacco = df2.loc[(df2[\"Measure Title\"]==\"Preventive Care and Screening: Tobacco Use: Screening and Cessation Intervention\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df10_osteo = df2.loc[(df2[\"Measure Title\"]==\"Screening or Therapy for Osteoporosis for Women Aged 65 Years and Older\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "df11_ecg = df2.loc[(df2[\"Measure Title\"]==\"Emergency Medicine: 12-Lead Electrocardiogram (ECG) Performed for Non-Traumatic Chest Pain\"),[\"NPI\",\"Measure Performance Rate\"]]\n",
    "\n",
    "brcancm=pd.merge(am, df4_brcanc, on='NPI').drop_duplicates().dropna()\n",
    "brcancf=pd.merge(af, df4_brcanc, on='NPI').drop_duplicates().dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colocanc_tobacco=pd.merge(ips15.loc[(ips15['measure_title']=='Colorectal Cancer Screening'),['NPI','prf_rate']],ips15.loc[(ips15['measure_title']=='Preventive Care and Screening: Tobacco Use: Screening and Cessation Intervention'),['NPI','prf_rate']], on='NPI').drop_duplicates().dropna()\n",
    "flu_pneuvacc=pd.merge(ips15.loc[(ips15['measure_title']=='Preventive Care and Screening: Influenza Immunization'),['NPI','prf_rate']],ips15.loc[(ips15['measure_title']=='Pneumonia Vaccination Status for Older Adults'),['NPI','prf_rate']], on='NPI').drop_duplicates().dropna()\n",
    "brcancm = pd.merge(ips15.loc[(ips15['measure_title']=='Breast Cancer Screening'),['NPI','prf_rate']],ndf15.loc[(ndf15.gndr=='M'),['NPI','Grd_yr']],on='NPI').drop_duplicates().dropna()\n",
    "brcancf = pd.merge(ips15.loc[(ips15['measure_title']=='Breast Cancer Screening'),['NPI','prf_rate']],ndf15.loc[(ndf15.gndr=='F'),['NPI','Grd_yr']],on='NPI').drop_duplicates().dropna()\n",
    "flum = pd.merge(ips15.loc[(ips15['measure_title']=='Preventive Care and Screening: Influenza Immunization'),['NPI','prf_rate']],ndf15.loc[(ndf15.gndr=='M'),['NPI','Grd_yr']],on='NPI').drop_duplicates().dropna()\n",
    "fluf = pd.merge(ips15.loc[(ips15['measure_title']=='Preventive Care and Screening: Influenza Immunization'),['NPI','prf_rate']],ndf15.loc[(ndf15.gndr=='F'),['NPI','Grd_yr']],on='NPI').drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = colocanc_tobacco.plot.scatter(x='prf_rate_x',y='prf_rate_y',title='Coincidence of performance scores in Colon Cancer Prevention and Smoking Intervention')\n",
    "ax.set(xlabel='Colon Cancer Screening performance rate', ylabel='Smoking Intervention')\n",
    "print(scipy.stats.describe(colocanc_tobacco.prf_rate_x))\n",
    "print(scipy.stats.describe(colocanc_tobacco.prf_rate_y))\n",
    "print(stats.ttest_ind(colocanc_tobacco.prf_rate_x,colocanc_tobacco.prf_rate_y,equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis confirms the surprising result seen above. Clinicians who had scores in both categories did an excellent job of counseling their patients with regards to Smoking Cessation (mean value ~95), but those same clinicians did much more poorly when it came to Colorectal Cancer Screening (mean value ~56). Colorectal cancers affect mosly older adults, and the prognosis of those suffering from such cancers drops sharply with disease progression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Clinician Performance Score for Breast Cancer Screening', fontsize=20)\n",
    "plt.xlabel('Clinician Graduation Year')\n",
    "plt.ylabel('Performance Score')\n",
    "ax1=plt.scatter(brcancm.Grd_yr, brcancm.prf_rate, c='blue', s=0.4, label='Male')\n",
    "ax2=plt.scatter(brcancf.Grd_yr, brcancf.prf_rate, c='red', s=0.4, label='Female')\n",
    "plt.gca().legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Clinician Performance Score for Breast Cancer Screening',fontsize=20)\n",
    "plt.xlabel('Performance Score for Breast Cancer Screening')\n",
    "plt.ylabel('Normalized Frequency')\n",
    "ax1=plt.hist(brcancm.prf_rate, label=\"Male\", bins=dp, color='blue', normed=True)\n",
    "ax2=plt.hist(brcancf.prf_rate, label=\"Female\", bins=dp, color='red', normed=True, alpha=0.25)\n",
    "plt.gca().legend()\n",
    "plt.show()\n",
    "print(stats.ttest_ind(brcancm.prf_rate,brcancf.prf_rate,equal_var=False))\n",
    "print(scipy.stats.describe(brcancm.prf_rate))\n",
    "print(scipy.stats.describe(brcancf.prf_rate))\n",
    "print(1-57.528294367693945/63.06273836765828)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Female clinicians perform significantly (p = 1e-31) better at Breast Cancer Screening than do their Male counterparts, with the Male mean score ~9% lower than that of the Female mean score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Clinician Performance Score for Influenza Administration', fontsize=20)\n",
    "plt.xlabel('Clinician Graduation Year')\n",
    "plt.ylabel('Performance Score')\n",
    "ax1=plt.scatter(flum.Grd_yr, flum.prf_rate, c='blue', s=0.4, label='Male')\n",
    "ax2=plt.scatter(fluf.Grd_yr, fluf.prf_rate, c='red', s=0.4, label='Female')\n",
    "plt.gca().legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Clinician Performance Score for Influenza Immunization',fontsize=20)\n",
    "plt.xlabel('Score for Influenza Immunization')\n",
    "plt.ylabel('Normalized Frequency')\n",
    "ax1=plt.hist(flum.prf_rate, label=\"Male\", bins=dp, color='blue', normed=True)\n",
    "ax2=plt.hist(fluf.prf_rate, label=\"Female\", bins=dp, color='red', normed=True, alpha=0.25)\n",
    "plt.gca().legend()\n",
    "plt.show()\n",
    "print(stats.ttest_ind(flum.prf_rate,fluf.prf_rate,equal_var=False))\n",
    "print(scipy.stats.describe(flum.prf_rate))\n",
    "print(scipy.stats.describe(fluf.prf_rate))\n",
    "print(1-scipy.stats.describe(flum.prf_rate).mean/scipy.stats.describe(fluf.prf_rate).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Female clinicians perform significantly (p = 7e-08) better at Influenza Immunization than do their Male counterparts, with the Male mean score ~5% lower than that of the Female mean score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = np.linspace(1945,2020,16)\n",
    "a15 = pd.value_counts(ndf15.loc[(ndf15['PQRS']=='Y'),['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "b15 = pd.value_counts(ndf15[['NPI','Grd_yr']].drop_duplicates().dropna().Grd_yr, bins=dy, sort=False)\n",
    "c15 = a15/b15\n",
    "ax = c15.plot.bar(ylim=(0,0.7), title='Clinician Participation Rate vs Year of Terminal Degree (2015 Data)')\n",
    "ax.set(xlabel=\"Year of Clinician's Terminal Degree\", ylabel=\"Clinician participation rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = flu_pneuvacc.plot.scatter(x='prf_rate_x',y='prf_rate_y',title='Coincidence of performance scores in Influenza Immunization and Pneumonia Vaccination')\n",
    "ax.set(xlabel='Influenza Immunization Score', ylabel='Pneumonia Vaccination Score')\n",
    "print(scipy.stats.describe(flu_pneuvacc.prf_rate_x))\n",
    "print(scipy.stats.describe(flu_pneuvacc.prf_rate_y))\n",
    "print(stats.ttest_ind(flu_pneuvacc.prf_rate_x,flu_pneuvacc.prf_rate_y,equal_var=False))\n",
    "print(1-scipy.stats.describe(flu_pneuvacc.prf_rate_x).mean/scipy.stats.describe(flu_pneuvacc.prf_rate_y).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On average clinicians do a significantly worse (p = 4e-237) job counseling their patients regarding Influenza Vaccination (mean score = 50.8, 18% lower than for Pneumonia Vaccination) than they do regarding Pneumonia Vaccination (mean score = 61.8). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Progress, need to vectorize loops(!) and extend into the measure_ID dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section collects descriptive statistics on the performance data of clinicians by their primary specialty, generating a\n",
    "## dataframe in which the columns are specialties and the columns are the various measurement categories covered by the PQRS\n",
    "## As of now this works on only a single category, and compares clinician primary specialties within that category.\n",
    "## This needs to be vectorized badly, extremely slow as nested for loops.\n",
    "\n",
    "spec_list = ndf15.pri_spec.unique()\n",
    "measure_ID_list = ips15.measure_ID.unique()\n",
    "spec_mid_descstat = pd.DataFrame(index=np.arange(0, len(spec_list)), columns=measure_ID_list)\n",
    "\n",
    "for i in range(0, len(measure_ID_list)):\n",
    "    a = ips15.loc[(ips15['measure_ID']==measure_ID_list[i]),['NPI', 'prf_rate', 'patient_count']].drop_duplicates().dropna()\n",
    "    for j in range(0, len(spec_list)):\n",
    "        b = ndf15.loc[(ndf15['pri_spec']==spec_list[j]),['NPI']].drop_duplicates().dropna()\n",
    "        c = pd.merge(a, b, on='NPI')\n",
    "        if not c.prf_rate.empty:\n",
    "            d = scipy.stats.describe(c.prf_rate)\n",
    "            e = c.patient_count.sum()\n",
    "            spec_mid_descstat.iat[j,i] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttests between specialties for a given performance measure\n",
    "\n",
    "spec_mid_ttests = pd.DataFrame(index=spec_list, columns=spec_list)\n",
    "\n",
    "for i in range(0, len(spec_list)):\n",
    "    for j in range(0, len(spec_list)):\n",
    "        if not pd.isnull(spec_mid_descstat.iat[i,0])|pd.isnull(spec_mid_descstat.iat[j,0]) :\n",
    "            d = scipy.stats.ttest_ind_from_stats(mean1=spec_mid_descstat.iat[i,0].mean, std1=np.sqrt(spec_mid_descstat.iat[i,0].variance), nobs1=spec_mid_descstat.iat[i,0].nobs, mean2=spec_mid_descstat.iat[j,0].mean, std2=np.sqrt(spec_mid_descstat.iat[j,0].variance), nobs2=spec_mid_descstat.iat[j,0].nobs, equal_var=False)\n",
    "            spec_mid_ttests.iat[j,i] = d\n",
    "        else:\n",
    "            spec_mid_ttests.iat[j,i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_mid_ttests\n",
    "# Construct heatmap using pvalues?\n",
    "spec_mid_ttests.iat[3,0].pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
